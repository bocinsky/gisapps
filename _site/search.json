[
  {
    "objectID": "content/01-content.html",
    "href": "content/01-content.html",
    "title": "Introduction",
    "section": "",
    "text": "Syllabus and learning objectives\nReview\n\nPopulation and samples\nObservational versus experimental studies\nSampling schemes: random, stratified and cluster sampling\n\nIntroduction to experimental designs\nTerminology of experimental design\nRequirements for a good experiment"
  },
  {
    "objectID": "content/01-content.html#learning-objectives",
    "href": "content/01-content.html#learning-objectives",
    "title": "Introduction",
    "section": "Learning objectives",
    "text": "Learning objectives\n\nLearning the terminology associated to experiments.\nAssessing the generalizability of a study based on the consideration of the sample characteristics, sampling scheme and population.\nDistinguishing between observational and experimental studies.\nUnderstanding the rationale behind the requirements for good experimental studies."
  },
  {
    "objectID": "content/01-content.html#preliminaries",
    "href": "content/01-content.html#preliminaries",
    "title": "Introduction",
    "section": "Preliminaries",
    "text": "Preliminaries\n\nFamiliarize yourself with the syllabus, content, examples, and evaluations pages for this class.\n Read Chapter 1 (Intro to Data) of OpenIntro Statistics and the accompanying  videos"
  },
  {
    "objectID": "content/01-content.html#readings",
    "href": "content/01-content.html#readings",
    "title": "Introduction",
    "section": "Readings",
    "text": "Readings\n\n\n\n\n\n\nWarning\n\n\n\nThese readings should be completed before class, to ensure timely understanding and let us discuss the concepts together through various examples and case studies — the strict minimum being the course notes. If you feel a section is redundant and overlaps with the latter, feel free to skim through the rest of the material.\n\n\n\n Chapter 1 of the Course notes\n Chapter 2 of Introduction to Modern Statistics\n\nFeel free to inform me in the weekly check-in of your take on these references."
  },
  {
    "objectID": "content/01-content.html#complementary-readings",
    "href": "content/01-content.html#complementary-readings",
    "title": "Introduction",
    "section": "Complementary readings",
    "text": "Complementary readings\n\n\n\n\n\n\nWarning\n\n\n\nComplementary readings are additional sources of information that are not required readings, but may be useful substitutes. Sometimes, they go beyond the scope of what we cover (in more details).\n\n\n\n Chapter 1 (Preliminaries) in Planning of experiments (Cox, 1958). Out of print, but addresses the basic concepts using a variety of examples (mostly from agricultural field trials), and particularly well written.\n Chapter 1 and Sections 2.1-2.2 in Design and Analysis of Experiments (Dean et al., 2017)"
  },
  {
    "objectID": "content/01-content.html#slides",
    "href": "content/01-content.html#slides",
    "title": "Introduction",
    "section": "Slides",
    "text": "Slides\nThe slides for today’s lesson are available online as an HTML file. Use the buttons below to open the slides either as an interactive website or as a static PDF (for printing or storing for later). You can also click in the slides below and navigate through them with your left and right arrow keys.\n\n View all slides in new window  Download PDF of all slides\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nFun fact: If you type ? (or shift + /) while going through the slides, you can see a list of slide-specific commands."
  },
  {
    "objectID": "content/01-content.html#case-study",
    "href": "content/01-content.html#case-study",
    "title": "Introduction",
    "section": "Case study",
    "text": "Case study\nWe will discuss the summary of Abaluck et al. (2022) “The Impact of Mask Distribution and Promotion on Mask Uptake and COVID-19 in Bangladesh” in class.\nDuring the activity, you will be asked to identify in teams the following:\n\nthe objective of the study\nthe target population (which findings generalize?)\nthe sampling scheme\nthe observational and experimental units\nthe treatments\nthe outcome variable(s)"
  },
  {
    "objectID": "content/02-content.html",
    "href": "content/02-content.html",
    "title": "Hypothesis testing",
    "section": "",
    "text": "Sampling variability\nHypothesis testing\nPairwise comparisons"
  },
  {
    "objectID": "content/02-content.html#learning-objectives",
    "href": "content/02-content.html#learning-objectives",
    "title": "Hypothesis testing",
    "section": "Learning objectives",
    "text": "Learning objectives\nAt the end of the session, students should be capable of\n\nunderstanding the mechanics behind generic hypothesis tests\ninterpreting the output of generic tests\ncorrectly reporting the output of a testing procedure"
  },
  {
    "objectID": "content/02-content.html#readings",
    "href": "content/02-content.html#readings",
    "title": "Hypothesis testing",
    "section": "Readings",
    "text": "Readings\n\n Chapter 2 of the Course notes\n Chapter 5 (Foundations for inference) of Matthew Crump’s course notes\n The permutation test by Jared Wilson"
  },
  {
    "objectID": "content/02-content.html#complementary-readings",
    "href": "content/02-content.html#complementary-readings",
    "title": "Hypothesis testing",
    "section": "Complementary readings",
    "text": "Complementary readings\n\n Chapter 3 of Keppel & Wickens (2004)."
  },
  {
    "objectID": "content/02-content.html#slides",
    "href": "content/02-content.html#slides",
    "title": "Hypothesis testing",
    "section": "Slides",
    "text": "Slides\n\n View all slides in new window  Download PDF of all slides\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nFun fact: If you type ? (or shift + /) while going through the slides, you can see a list of slide-specific commands."
  },
  {
    "objectID": "content/02-content.html#case-study",
    "href": "content/02-content.html#case-study",
    "title": "Hypothesis testing",
    "section": "Case study",
    "text": "Case study\nWe will look at the way authors report the conclusion of their statistical tests with\n\nRosen & Jerdee (1974)\nBrucks & Levav (2022)\nLiu et al. (2022+), Experiment 1"
  },
  {
    "objectID": "content/03-content.html",
    "href": "content/03-content.html",
    "title": "Analysis of variance",
    "section": "",
    "text": "ANOVA and F-test statistic\nPower of the F-test\nModel assumptions"
  },
  {
    "objectID": "content/03-content.html#learning-objectives",
    "href": "content/03-content.html#learning-objectives",
    "title": "Analysis of variance",
    "section": "Learning objectives",
    "text": "Learning objectives\nAt the end of the session, students should be capable of\n\ncarry-out a one-way analysis of variance test\nlist and explain which factors impact the power of the F-test\ncheck model assumptions using hypothesis tests and graphics."
  },
  {
    "objectID": "content/03-content.html#readings",
    "href": "content/03-content.html#readings",
    "title": "Analysis of variance",
    "section": "Readings",
    "text": "Readings\n\n Chapter 3 of the Course notes"
  },
  {
    "objectID": "content/03-content.html#complementary-readings",
    "href": "content/03-content.html#complementary-readings",
    "title": "Analysis of variance",
    "section": "Complementary readings",
    "text": "Complementary readings\n\n Chapter 2 of Meier (2022)\n Chapter 3 and 7 of Keppel & Wickens (2004)."
  },
  {
    "objectID": "content/03-content.html#slides",
    "href": "content/03-content.html#slides",
    "title": "Analysis of variance",
    "section": "Slides",
    "text": "Slides\n\n View all slides in new window  Download PDF of all slides\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nFun fact: If you type ? (or shift + /) while going through the slides, you can see a list of slide-specific commands."
  },
  {
    "objectID": "content/04-content.html",
    "href": "content/04-content.html",
    "title": "Contrasts and multiple testing",
    "section": "",
    "text": "Contrasts\nMultiple testing"
  },
  {
    "objectID": "content/04-content.html#learning-objectives",
    "href": "content/04-content.html#learning-objectives",
    "title": "Contrasts and multiple testing",
    "section": "Learning objectives",
    "text": "Learning objectives\nAt the end of the session, students should be capable of\n\nspecifying and calculating custom contrasts in factorial designs\ndetermining the number of tests in a family that need to be corrected for\nunderstanding how to correct p-values to account for multiple testing\nlisting multiplicity testing methods suitable depending on context"
  },
  {
    "objectID": "content/04-content.html#readings",
    "href": "content/04-content.html#readings",
    "title": "Contrasts and multiple testing",
    "section": "Readings",
    "text": "Readings\n\n Chapter of Meier (2022)\n One-way ANOVA example"
  },
  {
    "objectID": "content/04-content.html#complementary-readings",
    "href": "content/04-content.html#complementary-readings",
    "title": "Contrasts and multiple testing",
    "section": "Complementary readings",
    "text": "Complementary readings\n\n Chapters 4 and 6 of Keppel & Wickens (2004)."
  },
  {
    "objectID": "content/04-content.html#slides",
    "href": "content/04-content.html#slides",
    "title": "Contrasts and multiple testing",
    "section": "Slides",
    "text": "Slides\n\n View all slides in new window  Download PDF of all slides\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nFun fact: If you type ? (or shift + /) while going through the slides, you can see a list of slide-specific commands."
  },
  {
    "objectID": "content/index.html",
    "href": "content/index.html",
    "title": "Readings, lectures, and videos",
    "section": "",
    "text": "Every class session also has a YouTube playlist of short recorded videos for each of the lecture sections. The lecture slides are special HTML files made with the R package xaringan . On each class session page you’ll see buttons for opening the presentation in a new tab or for downloading a PDF of the slides in case you want to print them or store them on your computer:\n\n View all slides in new window  Download PDF of all slides\n\nThe slides are also embedded on each page. You can click in the slides and navigate through them with ← and →. If you type ? (or shift + /) while viewing the slides you can see a list of slide-specific commands (like f for fullscreen or p for presenter mode if you want to see my notes)."
  },
  {
    "objectID": "evaluations/01-problem-set.html",
    "href": "evaluations/01-problem-set.html",
    "title": "Problem set 1",
    "section": "",
    "text": "Task 2: Getting started with programming\nStarting from next week, you will need to perform statistical analyses using a suitable software of your choosing.\nYour job is to install a software of your liking. Tell me which one you chose and report back on your success! Also go through tutorials to get started with loading data, producing basic plots and computing simple descriptive statistics.\n\n\n\n\n\n\nReferences\n\nClayton, A. (2018). Do gender quotas really reduce bias? Evidence from a policy experiment in Southern Africa. Journal of Experimental Political Science, 5(3), 182--194. https://doi.org/10.1017/XPS.2018.8\n\n\nGoldstein, N. J., Cialdini, R. B., & Griskevicius, V. (2008). A room with a viewpoint: Using social norms to motivate environmental conservation in hotels. Journal of Consumer Research, 35(3), 472–482. https://doi.org/10.1086/586910"
  },
  {
    "objectID": "evaluations/02-problem-set.html",
    "href": "evaluations/02-problem-set.html",
    "title": "Problem set 2",
    "section": "",
    "text": "Task 2 - Reproducibility\nSection 3.2 of Duke & Amir (2022) report the results of an online experiment and the impact on sales of sequential vs integrated decision making; the data can be found in the R package hecedsm under DA22_E2; you can also download the SPSS database.\nReproduce the results reported in Section 3.2.2 and check that your results match those of the paper. Submit your code alongside your report.\n\n\n\n\n\n\nReferences\n\nBastian, B., Jetten, J., & Ferris, L. J. (2014). Pain as social glue: Shared pain increases cooperation. Psychological Science, 25(11), 2079–2085. https://doi.org/10.1177/0956797614545886\n\n\nDuke, K. E., & Amir, O. (2022). The importance of selling formats: When integrating purchase and quantity decisions increases sales. Marketing Science, In press. https://doi.org/10.1287/mksc.2022.1364\n\nFootnotes\n\n\nWe will see modelling assumptions in Week 3, take my word on it for now.↩︎"
  },
  {
    "objectID": "evaluations/03-problem-set.html",
    "href": "evaluations/03-problem-set.html",
    "title": "Problem set 3",
    "section": "",
    "text": "a PDF report\nyour code\n\nfollowing the naming convention PS3-studentid.extension where studentid is replaced with your student ID and extension is the file extension (e.g., .pdf, .R, .Rmd, .sps)\nInstructions: We consider data collected for Study 3 of Grossmann & Kross (2014) (click the links to download the paper and the Supplementary material). You can access these data directly from R from the hecedsm package or download the SPSS data.\nHave a quick look at the paper and fit the one way analysis of variance model to responses for young adults (20 to 40 years) only.\n\nReport the test statistic, the null distribution and the p-value.\nProvide a conclusion in the context of the study.\nThere are missing values (see code output below). One thing to check normally is whether the lack of response is due to the treatment (for example, tasks that are more difficult or longer lead to higher dropout rate). Using the code provided below, inspect the pattern. Do you think there is a cause for concern in the present context?\n\nWe next look at model assumptions\n\nIs the independence assumption plausible in the context?\nHow many observations are there in each group (excluding missing values)? Is the number sufficient to reliably estimate the sample mean of each experimental condition and forego normality checks?\nProduce a normal quantile-quantile plot and comment on the distribution of the residuals (check out this response on CrossValidated first).\nCheck the equality of variance assumption using a suitable test statistic and report the results.\nUse Welch’s one-way analysis of variance model (oneway.test() in R) and compare the output and the conclusion with that of the usual \\(F\\)-test.\n\nHints and R snippets\nTo subset the data, you can use the following commands:\n\ndata(GK14_S3, package = \"hecedsm\")\ndb <- GK14_S3 |>\n    dplyr::filter(\n      !is.na(persp), # exclude missing values\n      age == \"young\") # only young adults\n\nThe following code filters out missing values for persp for young adults and shows the counts for each condition:\n\nGK14_S3 |>\n  dplyr::filter(is.na(persp),      \n                age == \"young\") |> \n  dplyr::group_by(condition) |> \n  dplyr::summarize(count = dplyr::n()) \n\n# A tibble: 4 × 2\n  condition       count\n  <fct>           <int>\n1 self immersed       3\n2 self distanced      3\n3 other immersed      3\n4 other distanced     2\n\n\nand finally the following code chunk creates box and whiskers plots and overlays the (jittered) data.\n\nlibrary(ggplot2) # grammar of graphics\nggplot(data = db,\n       mapping = aes(x = condition,\n                     y = persp,\n                     color = condition)) +\n  geom_boxplot() +\n  geom_jitter()\n\n\n\n\n\n\n\n\nReferences\n\nGrossmann, I., & Kross, E. (2014). Exploring Solomon’s paradox: Self-distancing eliminates the self-other asymmetry in wise reasoning about close relationships in younger and older adults. Psychological Science, 25(8), 1571–1580. https://doi.org/10.1177/0956797614535400"
  },
  {
    "objectID": "evaluations/final-exam.html",
    "href": "evaluations/final-exam.html",
    "title": "Final examination",
    "section": "",
    "text": "The exam format is as follows:\n\nOne question on the fundamentals of experimental designs (blocking, randomization, etc.)\nOne question on reproducibility/replication crisis\nOne question on key concepts (power, effect size, multiple testing).\nOne question on advanced topics (mixed models, causal inference and mediation analysis, etc.)\nTwo data analysis questions, using completely randomized or blocked designs (between-subjects or within-subject) with multi-way analysis of variance, ANCOVA, mixed model, with specific questions on various aspects including\n\nparametrization of ANOVA\nadequate setup of model\ninteraction plots\nuse of different tests and methods\ncalculation of degrees of freedom of the model / sample size\nconclusions related to output of tests\ninterpretation of effect sizes\ncontrasts and pairwise comparisons\ntests for model assumptions and diagnostic plots\n\n\nA practice final can be downloaded here"
  },
  {
    "objectID": "evaluations/index.html",
    "href": "evaluations/index.html",
    "title": "Evaluations",
    "section": "",
    "text": "The main goals of this class are to help you understand the steps require to design and analyse the results of an experiment."
  },
  {
    "objectID": "evaluations/index.html#weekly-check-in",
    "href": "evaluations/index.html#weekly-check-in",
    "title": "Evaluations",
    "section": "Weekly check-in",
    "text": "Weekly check-in\nI want to hear back from you regarding the course material, activities and learning material.\nI will grade these check-ins using a check system:\n\n✔+: (115% in gradebook) Response shows phenomenal thought and engagement with the course content. I will not assign these often.\n✔: (100% in gradebook) Response is thoughtful, well-written, and shows engagement with the course content. This is the expected level of performance.\n✔−: (50% in gradebook) Response is hastily composed, too short, and/or only cursorily engages with the course content. This grade signals that you need to improve next time. I will hopefully not assign these often.\n\nNotice that is essentially a pass/fail or completion-based system. I’m not grading your writing ability, I’m not counting the exact number of words you’re writing, and I’m not looking for encyclopedic citations of every single reading to prove that you did indeed read everything. I’m looking for thoughtful engagement, that’s all. Do good work and you’ll get a ✔.\nYou will submit these responses via ZoneCours."
  },
  {
    "objectID": "evaluations/index.html#problem-sets",
    "href": "evaluations/index.html#problem-sets",
    "title": "Evaluations",
    "section": "Problem sets",
    "text": "Problem sets\nThere are 12 problem sets on the schedule. I will keep the highest grades for 11 of them. I will drop the lowest score - this means you can skip one of the problem sets. You need to show that you made a good faith effort to work each question. I will not grade these in detail. The problem sets will be graded using a check system:\n\n✔+: (110% in gradebook) Assignment is 100% completed. Every question was attempted and answered, and most answers are correct. Document is clean and easy to follow. Work is exceptional. I will not assign these often.\n✔: (100% in gradebook) Assignment is 70–99% complete and most answers are correct. This is the expected level of performance.\n✔−: (50% in gradebook) Assignment is less than 70% complete and/or most answers are incorrect. This indicates that you need to improve next time. I will hopefully not assign these often.\n\nYou may (and should!) work together on the problem sets, but you must turn in your own answers. You cannot work in groups of more than four people, and you must note who participated in the group in your assignment."
  },
  {
    "objectID": "evaluations/index.html#final-project",
    "href": "evaluations/index.html#final-project",
    "title": "Evaluations",
    "section": "Final project",
    "text": "Final project\nFor your final project, you will perform a critical review of a peer-reviewed paper from a list containing an experiment and which uses one of the statistical techniques covered in class. You will pay particular attention to reproducibility, readability and the correctness of the analysis, discussing points of improvement, statistical fallacies. This will help you develop skills for efficient peer-review of the statistical methodology section."
  },
  {
    "objectID": "evaluations/index.html#final-examination",
    "href": "evaluations/index.html#final-examination",
    "title": "Evaluations",
    "section": "Final examination",
    "text": "Final examination\nThere will be a closed-book final exam covering the content of the whole semester. Most of the questions will relate to the tasks you performed in problem set and to discussions we had in class. The exam will be in-person (see the Syllabus for details)."
  },
  {
    "objectID": "evaluations/paper-review.html",
    "href": "evaluations/paper-review.html",
    "title": "Paper review",
    "section": "",
    "text": "You will be assigned a scientific paper with open access material (data, code, etc.) to criticize. The purpose of the project is to let you practice peer-reviewing, focusing on reproducibility and correctness of the statistical analyses therein.\nComment on the methodology, the statistical analyses and the report of the statistical results in the paper. If your selected paper has more than one study, you will be assigned to a particular one for the purpose of the project.\nYou should focus on the following elements in your review:\n\nStrengths and weaknesses of the methodology used to test the research hypotheses.\nAppropriateness of experimental design and the choice of dependent variables, control variables, treatment conditions.\nAppropriateness of statistical analyses.\nPresentation and discussion of the results (e.g., descriptive statistics, estimation of effect sizes, power calculations, etc.)\nDiscussion of the limits of the study\nPossible sources of bias\nPre-registration, reproducibility and transparency of the study. Assessment of the potential for replicability.\n\nIn addition to the material seen in class, see Wilkinson (1999) and Campion (1993) to inform your review."
  },
  {
    "objectID": "evaluations/paper-review.html#deliverables",
    "href": "evaluations/paper-review.html#deliverables",
    "title": "Paper review",
    "section": "Deliverables",
    "text": "Deliverables\nA portable document file (PDF) of your critique (maximum 3 pages, excluding bibliography)"
  },
  {
    "objectID": "evaluations/paper-review.html#grading-rubric",
    "href": "evaluations/paper-review.html#grading-rubric",
    "title": "Paper review",
    "section": "Grading rubric",
    "text": "Grading rubric\n\nIdentification of strength and weaknesses: 10\nCorrectness of the interpretation of statistical results: 10\nScope: 10\nClarity of report: 10\nUsefulness of suggestions: 5\nWriting and referencing: 5"
  },
  {
    "objectID": "evaluations/weekly-check-in.html",
    "href": "evaluations/weekly-check-in.html",
    "title": "Questions",
    "section": "",
    "text": "You should answer the following three questions each week:\n\nWhat was the most exciting thing you learned from the session? Why?\nWhat was the muddiest thing from the session this week? What are you still wondering about?\n\nWhich activity did you find the most useful? What could have been skipped?"
  },
  {
    "objectID": "example/index.html",
    "href": "example/index.html",
    "title": "Examples",
    "section": "",
    "text": "Useful resources for learning R, the tidyverse and Rmarkdown basics include\n\nThe Introduction to R and RStudio by Open Intro Stat\nTeacups, giraffes & statistics: basic statistical concepts and programming\nthe notebook RYouWithMe from R-Ladies Sydney\nthe book R for Data Science, which adheres to the tidyverse principles.\nthe R package DoSStoolkit, developped at the University of Toronto.\nthe introverse documentation.\nthe RStudio cheatsheets, also available from RStudio menu in Help > Cheat Sheets\n\nTo install all R packages used throughout the course, use the command\n\n\nCode\nlib <- c(\"afex\", \"car\", \"emmeans\", \"effectsize\", \"lme4\", \n         \"lmerTest\", \"nlme\", \"pwr\", \"tidyverse\", \"tidymodels\")\ninstall.packages(lib)"
  },
  {
    "objectID": "example/installation.html",
    "href": "example/installation.html",
    "title": "Installing R and RStudio",
    "section": "",
    "text": "Install R\nFirst you need to install the latest version of R itself (the engine), currently 4.2.1 (Funny-Looking Kid).\n\nGo to the Comprehensive R Archive Network (CRAN) website: https://cran.r-project.org/\nClick on “Download R for XXX”, where XXX is either Mac or Windows:\n\n\n\n\n\n\nIf you use macOS, scroll down to the first .pkg file in the list of files and download it.\n\n\n\n\n\nIf you use Windows, click “base” (or click on the bolded “install R for the first time” link) and download it.\n\n\n\n\n\n\nDouble click on the downloaded file (check your Downloads folder). Click yes through all the prompts to install like any other program.\nInstall OS specific programs\n\n\nmacOS only: download and install XQuartz.\nWindows only: download and install Rtools\n\n\n\nInstall RStudio\nNext, you need to install RStudio, the nicer graphical user interface (GUI) for R (the dashboard). Once R and RStudio are both installed, you can ignore R and only use RStudio. RStudio will use R automatically and you won’t ever have to interact with it directly.\n\nGo to the free download location on RStudio’s website: https://www.rstudio.com/products/rstudio/download/#download\nThe website should automatically detect your operating system (Linux, macOS or Windows) and show a big download button for it:\n\n\n\n\n\n\nIf not, scroll down a little to the large table and choose the version of RStudio that matches your operating system.\n\n\n\n\n\n\nDouble click on the downloaded file (again, check your Downloads folder). Click yes through all the prompts to install like any other program.\n\nDouble click on RStudio to run it (check your applications folder or start menu).\n\n\nInstall tidyverse\nR packages are easy to install with RStudio. Select the packages panel, click on “Install,” type the name of the package you want to install, and press enter.\n\n\n\n\n\nThis can sometimes be tedious when you’re installing lots of packages, though. The tidyverse, for instance, consists of dozens of packages (including ggplot2) that all work together. Rather than install each individually, you can install a single magical package and get them all at the same time.\nGo to the packages panel in RStudio, click on “Install,” type “tidyverse”, and press enter. You’ll see a bunch of output in the RStudio console as all the tidyverse packages are installed.\n\n\n\n\n\nNotice also that RStudio will generate a line of code for you and run it: install.packages(\"tidyverse\"). You can also just paste and run this instead of using the packages panel.\n\n\nInstall tinytex\nWhen you knit to PDF, R uses a special scientific typesetting program named LaTeX, which is complicated and a large download. To make life easier, there’s an R package named tinytex that installs a minimal LaTeX program and that automatically deals with differences between macOS and Windows.\nTo install tinytex:\n\nUse the Packages in panel in RStudio to install tinytex like you did above with tidyverse. Alternatively, run install.packages(\"tinytex\") in the console.\nRun tinytex::install_tinytex() in the console.\nWait for a bit while R downloads and installs everything you need.\nYou should now be able to knit to PDF."
  },
  {
    "objectID": "example/introduction.html",
    "href": "example/introduction.html",
    "title": "Introduction",
    "section": "",
    "text": "The code created in the video can be downloaded here.\nThere’s a set of videos that walks through each section below. To make it easier for you to jump around the video examples, I cut the long video into smaller pieces and included them all in one YouTube playlist.\n\nRStudio interface\nLoading data\nCleaning and transforming data\nSummary statistics\nCreating graphics\n\nYou can also watch the playlist (and skip around to different sections) here:"
  },
  {
    "objectID": "example/introduction.html#working-directory-and-packages",
    "href": "example/introduction.html#working-directory-and-packages",
    "title": "Introduction",
    "section": "Working directory and packages",
    "text": "Working directory and packages\nIf you start your analysis in a new project, the default directory is where the project lies: getwd() will indicate where R expects to see files. You can load packages using library, provided they have been installed beforehand using install.packages(). A package is a collection of function and datasets that you can access for various tasks: you need only buy a reference textbook once (installing packages), whereas you can read of anything if you take the book off your bookshelf from there onwards (loading the package). For the most part, we will work with the tidyverse package, a simple wrapper that loads multiple libraries that adhere to common principles (tidy data analysis) and whose code more closely ressemble logical workflow and proper English instructions than base R. However, the function syntax is not set in stone and evolves over time.\nYou will sometimes encounter the double colon syntax package::function: normally, you can only access functions and objects from packages that are loaded, but to avoid disambiguation and clarity it is sometimes helpful to specify directly which package the function is from (especially if many packages have functions that go by the same name). When you load a package, it will hide existing functions in already loaded packages: thus, but if you only need to access/use a single function from a package, it may be simpler to refer to it directly."
  },
  {
    "objectID": "example/introduction.html#importing-data",
    "href": "example/introduction.html#importing-data",
    "title": "Introduction",
    "section": "Importing data",
    "text": "Importing data\nThe data used in the course has been preprocessed and cleaned and can be directly adressed by name using the command\n\n\nCode\ndata(databasename, package = 'hecedsm')\n\n\nWarning in data(databasename, package = \"hecedsm\"): jeu de données\n'databasename' introuvable\n\n\nwhere databasename is replaced by the name of one of the datasets.\nIn more general settings, however, the first task you need to undertake is to download and manipulate the data in a format that is amenable to conducing statistical analysis. This can take many forms: data sets can be found directly in R packages, downloaded directly given a web address (URL) or else downloaded into a data folder and loaded into the environment.\nIt is good practice not to manipulate the raw data using a spreadsheet software like Microsoft Excel, which is infamous for it’s awkward manipulation (the French version Office doesn’t recognize or save .csv files as being comma-separated values, strings are converted to dates and numerical values, oftentimes inconsistantly, the number of columns is limited, etc. Rather, keep a copy of the raw data, a script in which you manipulate it and, if necessary, a clean and tidy version in another database. This ensures that you do not mistakenly change records and can easily modify your data analysis if you realize that the data were incorrect at some stage due to manipulation or incorrect interpretation.\nDepending on the format (particularly if you have SAS, SPSS or Stata formatted datasets, there may be hidden labels that contain information about the variables. The haven package, part of the tidyverse, imports the metadata alongside with the observations."
  },
  {
    "objectID": "example/introduction.html#study",
    "href": "example/introduction.html#study",
    "title": "Introduction",
    "section": "Study",
    "text": "Study\nWe consider data from Baumann et al. (1992). The abstract of the paper provides a brief description of the study\n\nThis study investigated the effectiveness of explicit instruction in think aloud as a means to promote elementary students’ comprehension monitoring abilities. Sixty-six fourth-grade students were randomly assigned to one of three experimental groups: (a) a Think-Aloud (TA) group, in which students were taught various comprehension monitoring strategies for reading stories (e.g., self-questioning, prediction, retelling, rereading) through the medium of thinking aloud; (b) a Directed reading-Thinking Activity (DRTA) group, in which students were taught a predict-verify strategy for reading and responding to stories; or (c) a Directed reading Activity (DRA) group, an instructed control, in which students engaged in a noninteractive, guided reading of stories.\n\nWe have multiple columns for each of the tests (pre-intervention and post-intervention) from Baumann et al. (1992). For the time being, we focus on the first, pretest, which was used to act as control and to ensure that the random allocation of students to the three treatment groups resulted in similar average performances. This allows allows us to perform paired comparisons at a later stage by subtracting post- and pre-intervention scores to check their progress.\nThe reader is invited at this stage to look at the description of the first task (Pretest 1) and the findings presented on p.148 of Baumann et al. (1992). We aim to reproduce their results here.\n\n\nCode\n# Load packages\nlibrary(tidyverse)\n# Load data from the package\ndata(BSJ92, package = 'hecedsm')\n# Look at data to check variable type\nglimpse(BSJ92)\n\n\nRows: 66\nColumns: 6\n$ group     <fct> DR, DR, DR, DR, DR, DR, DR, DR, DR, DR, DR, DR, DR, DR, DR, …\n$ pretest1  <int> 4, 6, 9, 12, 16, 15, 14, 12, 12, 8, 13, 9, 12, 12, 12, 10, 8…\n$ pretest2  <int> 3, 5, 4, 6, 5, 13, 8, 7, 3, 8, 7, 2, 5, 2, 2, 10, 5, 5, 3, 4…\n$ posttest1 <int> 5, 9, 5, 8, 10, 9, 12, 5, 8, 7, 12, 4, 4, 8, 6, 9, 3, 5, 4, …\n$ posttest2 <int> 4, 5, 3, 5, 9, 8, 5, 5, 7, 7, 4, 4, 6, 8, 4, 10, 3, 5, 5, 3,…\n$ posttest3 <int> 41, 41, 43, 46, 46, 45, 45, 32, 33, 39, 42, 45, 39, 44, 36, …\n\n\nIn R, categorical variables are stored as objects of type factor and numerical values as <dbl>, which stands for double.\nWe are now ready to proceed with the data analysis."
  },
  {
    "objectID": "example/introduction.html#summary-statistics",
    "href": "example/introduction.html#summary-statistics",
    "title": "Introduction",
    "section": "Summary statistics",
    "text": "Summary statistics\nWe have seen that although they may come from the same population, the sample estimates will never coincide with the population values exactly because of sampling variability. We compute summary statistics by treatment group: for this, we use the pipe, |>, which takes the object on the left and passes it on the right (this is the logical workflow), then group_by to split into separate groups and summarize to create a new tibble containing the descriptive statistics. The result is stored in summary_stats (note the assignment using the <- operator) on the first line.\n\n\nCode\nsummary_stats <- BSJ92 |>\n  group_by(group) |>\n  summarize(mean = mean(pretest1),\n            sd = sd(pretest1), # \"sd = standard deviation, i.e., sqrt(variance)\"\n            n = n()) \n\n\nWe can print the table in Rmarkdown.\n\n\n\nSummary statistics of pretest 1.\n \n  \n    group \n    mean \n    sd \n    n \n  \n \n\n  \n    DR \n    10.5 \n    3 \n    22 \n  \n  \n    DRTA \n    9.7 \n    3 \n    22 \n  \n  \n    TA \n    9.1 \n    3 \n    22 \n  \n\n\n\n\nCheck that the summary statistics match the ones reported in the paper.\nIf you pay closer attention to the data and their description, you will note that the response variable, which represents the number of correctly identified text insertions (out of 16) is discrete and bounded above by 16 and below by zero. The averages (and maximum) are high. The article mentions that the second task posttest1 was made more difficult due to fear that student improvement would lead them to successfully detect most statements (with more people getting the maximum possible score, thus making comparisons of capabilities more difficult). One would need to rescale the scores if we wished to make meaningful comparisons between the two because the denominator differ."
  },
  {
    "objectID": "example/introduction.html#graphics",
    "href": "example/introduction.html#graphics",
    "title": "Introduction",
    "section": "Graphics",
    "text": "Graphics\nSummary statistics are useful indicators, but they potentially hide aspects of the data. It is useful to plot the data (and sometimes include graphics in articles) to show the reader features or artefacts of the latter.\nOur data here consists of a categorical variable, group, and a numerical variable, pretest1. There are multiple choices of graphics, including dot plots, box-and-whisker plots, or simply scatterplots, jittered to avoid overplotting. These can be combined using raincloud plots. Below, I show a boxplot, the data points and finally the sample average.\nWe explore below some potential choices and present a final product that is camery-ready for publication. I strongly advice that you produce graphics that are standalone: they should be interpretable once extracted from the paper with their caption.\n\n\nCode\nset.seed(2021)\n# because of jittering below, the position changes\n# every time you generate the figure\n# the above ensures that the pseudo-random numbers\n# are the same (useful for papers!)\nggplot(data = BSJ92,\n       #aesthetics: which variables to map where\n       aes(x = group, \n           y = pretest1,\n           col = group)) +\n  geom_boxplot(\n    width = 0.2, # change width\n    position = position_nudge(x = -0.2, y = 0)) + \n  # offset to the left\n  # add rugs for observations\n  # move to right of boxplot\n  geom_point(shape = 95, # a horizontal bar\n             size = 4, # size of bar\n             alpha = 0.5, # transparency 1=opaque, 0=transparent\n             position = position_nudge(x = 0.2, y = 0)) +\n  # add averages\n  geom_point(data = summary_stats,\n             aes(y = mean),\n             shape = 4, # 4 is cross (x)\n             size = 2,# double size of point\n             position = position_nudge(x = -0.2, y = 0)) + \n  # add meaningful labels\n  labs(x = \"learning strategy\",\n       y = \"\", # put in subtitle (no head tilting)\n       title = \"Pre-test scores\",\n       subtitle = \"Number of sentences that don't belong to the story found (out of 16).\",\n       caption = \"Group averages are indicated with 'x'.\") + \n  theme_minimal() + # change theme (color of background, etc.)\n  theme(legend.position = \"none\") #remove legend\n\n\n\n\n\nResults of pretest 1 based on treatment allocation."
  },
  {
    "objectID": "example/onewayanova.html",
    "href": "example/onewayanova.html",
    "title": "One-way analysis of variance",
    "section": "",
    "text": "The code created in the video can be downloaded here.\nThere’s a set of videos that walks through each section below. To make it easier for you to jump around the video examples, I cut the long video into smaller pieces and included them all in one YouTube playlist.\n\nANOVA table\nContrasts and estimated marginal means\nMultiple testing\n\nYou can also watch the playlist (and skip around to different sections) here:"
  },
  {
    "objectID": "example/onewayanova.html#hypothesis-testing",
    "href": "example/onewayanova.html#hypothesis-testing",
    "title": "One-way analysis of variance",
    "section": "Hypothesis testing",
    "text": "Hypothesis testing\nWe can begin by testing whether the group average for the initial measurements at the beginning of the study, prior to any treatment) have the same mean. Strong indication against this null hypothesis would be evidence of a potential problem with the randomization. We compute the one-way analysis of variance table, which includes quantities that enter the F-statistic (named after its large-sample null distribution, which is an F-distribution).1\nWe use the lm function function to fit the model: an analysis of variance is a special case of linear model, in which the explanatory variables are categorical variables. The first argument of the function is a formula response ~ treatment, where treatment is the factor or categorical variable indicating the treatment.\nThe function anova is a method: when applied to the result of a call to lm, it produces an analysis of variance table including among other things the following information:\n\nthe value of the test statistic (F value)\nthe between and within sum of square (these are quantities that enter in the formula of the statistic)\nthe degrees of freedom of the F null distribution (column Df): these specify the parameters of the large-sample approximation for the null distribution, which is our default benchmark.\nthe mean square, which are sum of squares divided by the degrees of freedom.\nThe p-value (Pr(>F)), which gives the probability of observing an outcome as extreme if there was no difference.\n\nWe need to decide beforehand the level of the test (typically 5% or lower): this is the percentage of times we will reject the null hypothesis when its true based on observing an extreme outcome. We are asked to perform a binary decision (reject or fail to reject): if the p-value is less than the level, we ‘reject’ the null hypothesis of equal (population) means.\n\n\nCode\nmod_pre <- lm(formula = pretest1 ~ group,\n                     data = BSJ92)\nanova_tab <- broom::tidy(anova(mod_pre))\n# Save the output in a tibble to get more meaningful column names\n# Elements include `statistic`, `df`, `p.value`\n\n\n\n\n\nAnalysis of variance table for pre-test 1\n \n  \n    Terms \n    Degrees of freedom \n    Sum of squares \n    Mean square \n    Statistic \n    p-value \n  \n \n\n  \n    group \n    2 \n    20.58 \n    10.288 \n    1.13 \n    0.33 \n  \n  \n    Residuals \n    63 \n    572.45 \n    9.087 \n     \n     \n  \n\n\n\n\nThere isn’t strong evidence of difference in strength between groups prior to intervention. We can report the findings as follows:\nWe carried a one-way analysis for the pre-test results to ensure that the group abilities are the same in each treatment group; results show no significant differences at the 5% level (\\(F\\) (2, 63) = 1.13, \\(p\\) = 0.329).\nA similar result for the scores of the first post-test as response variable lead to strong evidence of difference between teaching methods.\n\n\n\n\n\n\nAnalysis of variance table for post-test 1\n \n  \n    Terms \n    Degrees of freedom \n    Sum of squares \n    Mean square \n    Statistic \n    p-value \n  \n \n\n  \n    group \n    2 \n    108.12 \n    54.061 \n    5.32 \n    0.01 \n  \n  \n    Residuals \n    63 \n    640.50 \n    10.167"
  },
  {
    "objectID": "example/onewayanova.html#contrasts-and-estimated-marginal-means",
    "href": "example/onewayanova.html#contrasts-and-estimated-marginal-means",
    "title": "One-way analysis of variance",
    "section": "Contrasts and estimated marginal means",
    "text": "Contrasts and estimated marginal means\nWhile the \\(F\\) test may strongly indicate that the means of each group are different, it doesn’t indicate which group is different from the rest. Because we can compare different groups doesn’t mean these comparisons are of any scientific interest and going fishing by looking at all pairwise differences is not necessarily the best strategy.\n\n\nCode\nlibrary(emmeans) #load package\nemmeans_post <- emmeans(object = mod_post, \n                        specs = \"group\")\n\n\n\n\n\n\nEstimated group averages with standard errors and 95% confidence intervals for post-test 1.\n \n  \n    Terms \n    Marginal mean \n    Standard error \n    Degrees of freedom \n    Lower limit (CI) \n    Upper limit (CI) \n  \n \n\n  \n    DR \n    6.68 \n    0.68 \n    63 \n    5.32 \n    8.04 \n  \n  \n    DRTA \n    9.77 \n    0.68 \n    63 \n    8.41 \n    11.13 \n  \n  \n    TA \n    7.77 \n    0.68 \n    63 \n    6.41 \n    9.13 \n  \n\n\n\n\n\nThus, we can see that DRTA has the highest average, followed by TA and directed reading (DR). The purpose of Baumann et al. (1992) was to make a particular comparison between treatment groups. From the abstract:\n\nThe primary quantitative analyses involved two planned orthogonal contrasts—effect of instruction (TA + DRTA vs. 2 x DRA) and intensity of instruction (TA vs. DRTA)—for three whole-sample dependent measures: (a) an error detection test, (b) a comprehension monitoring questionnaire, and (c) a modified cloze test.\n\nA contrast is a particular linear combination of the different groups, i.e., a sum of weighted mean the coefficients of which sum to zero. To test the hypothesis of Baumann et al. (1992) and writing \\(\\mu\\) to denote the population average, we have \\(\\mathscr{H}_0: \\mu_{\\mathrm{TA}} + \\mu_{\\mathrm{DRTA}} = 2 \\mu_{\\mathrm{DRA}}\\) or rewritten slightly \\[\\begin{align*}\n\\mathscr{H}_0: - 2 \\mu_{\\mathrm{DR}} + \\mu_{\\mathrm{DRTA}} + \\mu_{\\mathrm{TA}} = 0.\n\\end{align*}\\] with weights \\((-2, 1, 1)\\); the order of the levels for the treatment are (\\(\\mathrm{DRA}\\), \\(\\mathrm{DRTA}\\), \\(\\mathrm{TA}\\)) and it must match that of the coefficients. An equivalent formulation is \\((2, -1, -1)\\) or \\((1, -1/2, -1/2)\\): in either case, the estimated differences will be different (up to a constant multiple or a sign change). The vector of weights for \\(\\mathscr{H}_0: \\mu_{\\mathrm{TA}} = \\mu_{\\mathrm{DRTA}}\\) is, e.g.,(\\(0\\), \\(-1\\), \\(1\\)): the zero appears because the first component, \\(\\mathrm{DRA}\\) doesn’t appear. The two contrasts are orthogonal: these contrasts are special because the tests use disjoint bits of information about the sample.2\n\n\nCode\n# Identify the order of the level of the variables\nwith(BSJ92, levels(group))\n\n\n[1] \"DR\"   \"DRTA\" \"TA\"  \n\n\nCode\n# DR, DRTA, TA (alphabetical)\ncontrasts_list <- list(\n  \"C1: DRTA+TA vs 2DR\" = c(-2, 1, 1), \n  # Contrasts: linear combination of means, coefficients sum to zero\n  # 2xDR = DRTA + TA => -2*DR + 1*DRTA + 1*TA = 0 and -2+1+1 = 0\n  \"C1b: average (DRTA+TA) vs DR\" = c(-1, 0.5, 0.5), \n  #same thing, but halved so in terms of average\n  \"C2: DRTA vs TA\" = c(0, 1, -1),\n  \"C2: TA vs DRTA\" = c(0, -1, 1) \n  # same, but sign flipped\n)\ncontrasts_post <- \n  contrast(object = emmeans_post,\n           method = contrasts_list)\ncontrasts_summary_post <- summary(contrasts_post)\n\n\n\n\n\n\nEstimated contrasts for post-test 1.\n \n  \n    Contrast \n    Estimate \n    Standard error \n    Degrees of freedom \n    t statistic \n    p-value \n  \n \n\n  \n    C1: DRTA+TA vs 2DR \n    4.18 \n    1.67 \n    63 \n    2.51 \n    0.01 \n  \n  \n    C1b: average (DRTA+TA) vs DR \n    2.09 \n    0.83 \n    63 \n    2.51 \n    0.01 \n  \n  \n    C2: DRTA vs TA \n    2.00 \n    0.96 \n    63 \n    2.08 \n    0.04 \n  \n  \n    C2: TA vs DRTA \n    -2.00 \n    0.96 \n    63 \n    -2.08 \n    0.04 \n  \n\n\n\n\n\nWe can look at these differences; since DRTA versus TA is a pairwise difference, we could have obtained the \\(t\\)-statistic directly from the pairwise contrasts using pairs(emmeans_post). Note that the two different ways of writing the comparison between DR and the average of the other two methods yield different point estimates, but same inference (same \\(p\\)-values). For contrast \\(C_{1b}\\), we get half the estimate (but the standard error is also halved) and likewise for the second contrasts we get an estimate of \\(\\mu_{\\mathrm{DRTA}} - \\mu_{\\mathrm{TA}}\\) in the first case (\\(C_2\\)) and \\(\\mu_{\\mathrm{TA}} - \\mu_{\\mathrm{DRTA}}\\): the difference in group averages is the same up to sign.\nWhat is the conclusion of our analysis of contrasts? It looks like the methods involving teaching aloud have a strong impact on reading comprehension relative to only directed reading. The evidence is not as strong when we compare the method that combines directed reading-thinking activity and thinking aloud."
  },
  {
    "objectID": "example/onewayanova.html#multiple-testing",
    "href": "example/onewayanova.html#multiple-testing",
    "title": "One-way analysis of variance",
    "section": "Multiple testing",
    "text": "Multiple testing\nIn this example, we computed two contrasts (excluding the equivalent formulations) so since these comparisons are planned, we could provide the \\(p\\)-values as is. However, if we had computed many more tests, it would make sense to account for these so as not to inflate type I error (judicial mistake consisting in sending an innocent to jail).\n\n\nCode\ncontrasts_list <- list(\n  \"C1: DRTA+TA vs 2DR\" = c(-2, 1, 1), \n  \"C2: DRTA vs TA\" = c(0, 1, -1)\n)\ncontrasts_post_scheffe <- \n  contrast(object = emmeans_post,\n           method = contrasts_list,\n           adjust = \"scheffe\") # for arbitrary contrasts\n# extract p-values\npvals_scheffe <- summary(contrasts_post_scheffe)$p.value\npvals_scheffe\n\n\n[1] 0.04951625 0.12333575\n\n\nCode\n# Compute Bonferroni and Holm-Bonferroni correction\ncontrasts_post <- \n  contrast(object = emmeans_post,\n           method = contrasts_list,\n           adjust = \"none\") #default for custom contrasts\nraw_pval <- summary(contrasts_post)$p.value\np.adjust(p = raw_pval, method = \"bonferroni\")\n\n\n[1] 0.02920552 0.08313211\n\n\nCode\np.adjust(p = raw_pval, method = \"holm\") #Bonferroni-Holm method\n\n\n[1] 0.02920552 0.04156606\n\n\nIf we look at the p-values with the Scheffé’s method for custom contrasts, we get 0.015 for contrast 1 and 0.042 for contrast 2: since we are only making two tests here, these are much bigger than the \\(p\\)-values from Holm’s method which are 0.03 and 0.04. To try and avoid making type I error, we need to be more stringent to decide on rejection and this translates into bigger \\(p\\)-values, so lower power to detect. Try to use the less stringent method that still controls for the family wise error rate to preserve your power!"
  },
  {
    "objectID": "example/onewayanova.html#model-assumptions",
    "href": "example/onewayanova.html#model-assumptions",
    "title": "One-way analysis of variance",
    "section": "Model assumptions",
    "text": "Model assumptions\nSince we have no repeated measurements and there were no detectable difference apriori between students, we can postulate that the records are independent.\nWe could test whether the variance are equal: in this case, there is limited evidence of unequal variance. The data are of course not normal (because they consist of the counts of the number of insertions detected by pupils, which are integer-valued). However, we can see if there are extreme values and whether the residuals are far from normal. The simulated quantile-quantile plot shows that all points more or less align with the straight line and all fall within the confidence intervals, so there is no problem with this normality assumption (which anyway matters little).\nAre measurements additive? After assigning the pre-test 1, the experimenters adjusted the scale and made the post-test harder to avoid having maximum scores (considering that students also were more experienced).\n\nBecause the students performed at a higher-than-expected level on Pretest 1 (61% of all intruded sentences were correctly identified), the experimenters were concerned about a potential post-intervention ceiling effect on this posttest, an occurrence which could mask group differences. To reduce the likelihood of a ceiling effect, the intruded sentences for Posttest 1 were written so their inconsistencies were more subtle than those included in Pretest 1, which explains the somewhat lower level of performance on Posttest 1 (51% of all intruded sentences correctly identified).\n\nThis seems to have been successful since the maximum score is 15 out of 16 intrusions, while there were two students who scored 16 on the pre-test.\nThe next step is checking that the variability is the same in each group. Assuming equal variance is convenient because we can use more information (the whole sample) to estimate the level of uncertainty rather than solely the observations from each group. The more observations we use to estimate the variance, the more reliable our measure is (assuming that the variance were equal in each group to begin with).\n\n\nCode\n# test for equality of variance\ncar::leveneTest(posttest1 ~ group, data = BSJ92)\n\n\nLevene's Test for Homogeneity of Variance (center = median)\n      Df F value Pr(>F)\ngroup  2  2.1297 0.1273\n      63               \n\n\nCode\n# Quantile-quantile plot\ncar::qqPlot(x = mod_post, # lm object\n            ylab = 'empirical quantiles', # change y-axis label\n            id = FALSE) # Don't print to console 'outlying' observations\n\n\n\n\n\nCode\n# Residual plot (linearity, but useless for one way ANOVA)\ncar::residualPlot(mod_post)\n\n\n\n\n\nIf we were worried about the possibility of unequal variances, we could fit the model by estimating the variance separately in each group. This does not materially change the conclusions about teaching methods relative to the directed reading benchmark.\n\n\nCode\noneway.test(posttest1 ~ group, data = BSJ92)\n\n\n\n    One-way analysis of means (not assuming equal variances)\n\ndata:  posttest1 and group\nF = 6.9878, num df = 2.00, denom df = 41.13, p-value = 0.00244"
  },
  {
    "objectID": "example/onewayanova.html#auxiliary-and-concomitant-observation",
    "href": "example/onewayanova.html#auxiliary-and-concomitant-observation",
    "title": "One-way analysis of variance",
    "section": "Auxiliary and concomitant observation",
    "text": "Auxiliary and concomitant observation\nThe purpose of a good experimental design is to reduce the variability to better detect treatment effects. In the above example, we could have added a concomitant variable (the pre-test score) that captures the individual variability. This amounts to doing a paired comparison between post- and pre-test results. It helps with the analysis because it absorbs the baseline strength of individual students: by subtracting their records, we get their individual average out of the equation and thus there is less variability.\n\n\nCode\nanova_post_c <- lm(posttest1 ~ offset(pretest1) + group,\n                   data = BSJ92) \nanova_tab_c <- broom::tidy(anova(anova_post_c)) #anova table\n\n\nCompare this ANOVA table with the preceding. We could repeat the same procedure to compute the contrasts.\nUsing auxiliary information allows one to reduce the intrinsic variability: the estimated variance \\(\\widehat{\\sigma}^2\\) is 6.66 with the auxiliary information and 9.09 without: since we reduce the level of background noise, we get a higher signal-to-noise ratio. As a result, the p-value for the global test is smaller than with only posttest1 as response.\n\n\n\n\nAnalysis of variance table\n \n  \n    Terms \n    Degrees of freedom \n    Sum of squares \n    Mean square \n    Statistic \n    p-value \n  \n \n\n  \n    group \n    2 \n    168.21 \n    84.106 \n    12.64 \n    0 \n  \n  \n    Residuals \n    63 \n    419.32 \n    6.656"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Experimental Designs and Statistical Methods",
    "section": "",
    "text": "Instructor\n\n   Dr. Léo Belzile\n   4.850, Côte-Sainte-Catherine\n   leo.belzile@hec.ca\n\n\n\nCourse details\n\n   Fall 2022\n   Fridays\n   8:30-11:30\n   Côte-Sainte-Catherine, Groupe Deschênes\n\n\n\nContacting me\nI am best reached by email or Slack."
  },
  {
    "objectID": "schedule.html",
    "href": "schedule.html",
    "title": "Schedule",
    "section": "",
    "text": "Content (): This page contains the readings, slides, and recorded lectures for the week. Read and watch these before our in-person class.\nExample (): This page contains fully annotated R code and other supplementary information that you can use as a reference for your evaluations. This is only a reference page—you don’t have to necessarily do anything here. Some sections also contain videos of me live coding the examples so you can see what it looks like to work in real time. This page will be very helpful as you work on your evaluations.\nEvaluations (): This page contains the instructions for each evaluation. Weekly check-ins and problem sets are due by noon on the day before class.\n\n\n\n\n\n\n\n\n\n\nTitle\n\n\nContent\n\n\nExample\n\n\nEvaluations\n\n\n\n\n\n\nSession 1\n\n\n\n\nSeptember 2\n\n\nIntroduction to experimental designs and motivation\n\n\n\n\n\n\n\n\n\n\n\n\n\nSeptember 8\n\n\nWeekly check-in 1  (submit by 12:00:00)\n\n\n\n\n\n\n\n\n\n\n\n\n\nSeptember 8\n\n\nProblem set 1  (submit by 12:00:00)\n\n\n\n\n\n\n\n\n\n\n\n\n\nSession 2\n\n\n\n\nSeptember 9\n\n\nReview of key statistics concepts\n\n\n\n\n\n\n\n\n\n\n\n\n\nSeptember 15\n\n\nWeekly check-in 2  (submit by 12:00:00)\n\n\n\n\n\n\n\n\n\n\n\n\n\nSeptember 15\n\n\nProblem set 2  (submit by 12:00:00)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTitle\n\n\nContent\n\n\nExample\n\n\nEvaluations\n\n\n\n\n\n\nSession 3\n\n\n\n\nSeptember 16\n\n\nCompletely randomized designs with one factor\n\n\n\n\n\n\n\n\n\n\n\n\n\nSeptember 22\n\n\nWeekly check-in 3  (submit by 12:00:00)\n\n\n\n\n\n\n\n\n\n\n\n\n\nSeptember 22\n\n\nProblem set 3  (submit by 12:00:00)\n\n\n\n\n\n\n\n\n\n\n\n\n\nSession 4\n\n\n\n\nSeptember 23\n\n\nContrasts and multiple testing\n\n\n\n\n\n\n\n\n\n\n\n\n\nSeptember 29\n\n\nWeekly check-in 4  (submit by 12:00:00)\n\n\n\n\n\n\n\n\n\n\n\n\n\nSeptember 29\n\n\nProblem set 4  (submit by 12:00:00)\n\n\n\n\n\n\n\n\n\n\n\n\n\nSession 5\n\n\n\n\nSeptember 30\n\n\nCompletely randomized designs with two factors\n\n\n\n\n\n\n\n\n\n\n\n\n\nOctober 6\n\n\nWeekly check-in 5  (submit by 12:00:00)\n\n\n\n\n\n\n\n\n\n\n\n\n\nOctober 6\n\n\nProblem set 5  (submit by 12:00:00)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTitle\n\n\nContent\n\n\nExample\n\n\nEvaluations\n\n\n\n\n\n\nSession 6\n\n\n\n\nOctober 7\n\n\nBlock designs and analysis of covariance\n\n\n\n\n\n\n\n\n\n\n\n\n\nOctober 13\n\n\nWeekly check-in 6  (submit by 12:00:00)\n\n\n\n\n\n\n\n\n\n\n\n\n\nOctober 13\n\n\nProblem set 6  (submit by 12:00:00)\n\n\n\n\n\n\n\n\n\n\n\n\n\nBreak\n\n\n\n\nOctober 20–October 26\n\n\nFall break\n\n\n\n\n\n\n\n\n\n\n\n\n\nSession 7\n\n\n\n\nOctober 14\n\n\nEffect sizes and the replication crisis\n\n\n\n\n\n\n\n\n\n\n\n\n\nOctober 20\n\n\nWeekly check-in 7  (submit by 12:00:00)\n\n\n\n\n\n\n\n\n\n\n\n\n\nOctober 20\n\n\nProblem set 7  (submit by 12:00:00)\n\n\n\n\n\n\n\n\n\n\n\n\n\nSession 8\n\n\n\n\nOctober 28\n\n\nLinear model and nonparametric tests\n\n\n\n\n\n\n\n\n\n\n\n\n\nNovember 3\n\n\nWeekly check-in 8  (submit by 12:00:00)\n\n\n\n\n\n\n\n\n\n\n\n\n\nNovember 3\n\n\nProblem set 8  (submit by 12:00:00)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTitle\n\n\nContent\n\n\nExample\n\n\nEvaluations\n\n\n\n\n\n\nSession 9\n\n\n\n\nNovember 4\n\n\nRepeated measures\n\n\n\n\n\n\n\n\n\n\n\n\n\nNovember 10\n\n\nWeekly check-in 9  (submit by 12:00:00)\n\n\n\n\n\n\n\n\n\n\n\n\n\nNovember 10\n\n\nProblem set 9  (submit by 12:00:00)\n\n\n\n\n\n\n\n\n\n\n\n\n\nSession 10\n\n\n\n\nNovember 11\n\n\nMixed models\n\n\n\n\n\n\n\n\n\n\n\n\n\nNovember 17\n\n\nWeekly check-in 10  (submit by 12:00:00)\n\n\n\n\n\n\n\n\n\n\n\n\n\nNovember 17\n\n\nProblem set 10  (submit by 12:00:00)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTitle\n\n\nContent\n\n\nExample\n\n\nEvaluations\n\n\n\n\n\n\nSession 11\n\n\n\n\nNovember 18\n\n\nPower and intro to causal inference\n\n\n\n\n\n\n\n\n\n\n\n\n\nNovember 24\n\n\nWeekly check-in 11  (submit by 12:00:00)\n\n\n\n\n\n\n\n\n\n\n\n\n\nNovember 24\n\n\nProblem set 11  (submit by 12:00:00)\n\n\n\n\n\n\n\n\n\n\n\n\n\nSession 12\n\n\n\n\nNovember 25\n\n\nLinear mediation analysis\n\n\n\n\n\n\n\n\n\n\n\n\n\nDecember 1\n\n\nWeekly check-in 12  (submit by 12:00:00)\n\n\n\n\n\n\n\n\n\n\n\n\n\nDecember 1\n\n\nProblem set 12  (submit by 12:00:00)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTitle\n\n\nContent\n\n\nExample\n\n\nEvaluations\n\n\n\n\n\n\nSession 13\n\n\n\n\nDecember 2\n\n\nCategorical data and final review\n\n\n\n\n\n\n\n\n\n\n\n\n\nDecember 8\n\n\nWeekly check-in 13  (submit by 12:00:00)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTitle\n\n\nContent\n\n\nExample\n\n\nEvaluations\n\n\n\n\n\n\nEnd of term\n\n\n\n\nDecember 9\n\n\nPaper review  (submit by 23:55:00)\n\n\n\n\n\n\n\n\n\n\n\n\n\nDecember 13\n\n\nFinal exam  (submit by 13:30:00)"
  },
  {
    "objectID": "syllabus.html",
    "href": "syllabus.html",
    "title": "Syllabus",
    "section": "",
    "text": "Dr. Léo Belzile\n   4.850, Côte-Sainte-Catherine\n   leo.belzile@hec.ca\n\n\n\n\n\n   Fall 2022\n   Fridays\n   8:30-11:30\n   Côte-Sainte-Catherine, Groupe Deschênes"
  },
  {
    "objectID": "syllabus.html#learning-r",
    "href": "syllabus.html#learning-r",
    "title": "Syllabus",
    "section": "Learning R",
    "text": "Learning R\nSearching for help with R on Google can sometimes be tricky because the program name is a single letter. Google is generally smart enough to figure out what you mean when you search for “r scatterplot”, but if it does struggle, try searching for “rstats” instead (e.g., “rstats scatterplot”).\nCheck out StackOverflow (a Q&A site with hundreds of thousands of answers to all sorts of programming questions) and RStudio Community (a forum specifically designed for people using RStudio and the tidyverse)."
  },
  {
    "objectID": "syllabus.html#textbooks",
    "href": "syllabus.html#textbooks",
    "title": "Syllabus",
    "section": "Textbooks",
    "text": "Textbooks\nCourse notes for the class can be found online\nI will also assign readings from Meier (2022) ANOVA and Mixed Models: A Short Intro Using R, which is available online for free reading."
  },
  {
    "objectID": "syllabus.html#other-references",
    "href": "syllabus.html#other-references",
    "title": "Syllabus",
    "section": "Other references",
    "text": "Other references\nThere will occasionally be additional articles to read; links to these other resources will be included on the content page for that session.\nOther good references for (some or most of) the content we will cover includes\n\nKeppel & Wickens (2004): out of print; comprehensive reference with a focus on effect size and marginal effects, all calculations are done by hand.\nCox (1958): out of print, but beautifully written and nontechnical.\nDean et al. (2017): comprehensive and freely available via Springer link; students last year found it too dry and technical.\nBox et al. (1978).\nVanderWeele (2015).\nPearl et al. (2016)."
  },
  {
    "objectID": "syllabus.html#student-hours",
    "href": "syllabus.html#student-hours",
    "title": "Syllabus",
    "section": "Student hours",
    "text": "Student hours\nI am available Friday after class and from 13:30-15:00. My office, 4.850, is located next to the southern elevators in Côte-Sainte-Catherine building.\nPlease watch this video:\n\n\nStudent hours are set times dedicated to all of you (most professors call these “office hours”; I don’t3). This means that I will be in my office waiting for you to come by if you want to talk to me in person (or remotely) with whatever questions you have. This is the best and easiest way to find me and the best chance for discussing class material and concerns."
  },
  {
    "objectID": "syllabus.html#late-work",
    "href": "syllabus.html#late-work",
    "title": "Syllabus",
    "section": "Late work",
    "text": "Late work\nThe submission modules will stay open for two weeks after the due date for weekly check-in. As much as possible, we will discuss problem sets in class the day after they are due (provided all students have handed in their work). I will not assign penalties, but will gently nudge you to stay on track."
  },
  {
    "objectID": "syllabus.html#intellectual-integrity",
    "href": "syllabus.html#intellectual-integrity",
    "title": "Syllabus",
    "section": "Intellectual integrity",
    "text": "Intellectual integrity\nPlease don’t cheat! The official policy lists the school rules regarding plagiarism and academic integrity."
  },
  {
    "objectID": "syllabus.html#student-services",
    "href": "syllabus.html#student-services",
    "title": "Syllabus",
    "section": "Student services",
    "text": "Student services\nStudents with special needs should feel free to approach me so we can best discuss accommodations. Do check out HEC Montréal’s disabled students and [psychological] (https://www.hec.ca/en/students/support-resources/psychological-support/index.html) support services."
  },
  {
    "objectID": "syllabus.html#harassment-and-sexual-violence",
    "href": "syllabus.html#harassment-and-sexual-violence",
    "title": "Syllabus",
    "section": "Harassment and sexual violence",
    "text": "Harassment and sexual violence\nThe Center for Harassment Intervention (BIMH) is the unique access point for all members of the community subject to harassment or sexual violence. You can reach them at 514 343-7020 or by email at harcelement@hec.ca from Monday until Friday, from 8:30 until 4:30pm.\nIf you are in an emergency situation or fear for your safety, call emergency services at 911, followed by HEC Montréal security services at 514 340-6611.\nCheck the school official policy on these matters for more details."
  },
  {
    "objectID": "syllabus.html#family-policy",
    "href": "syllabus.html#family-policy",
    "title": "Syllabus",
    "section": "Family policy",
    "text": "Family policy\nHEC does not have an official family policy, so the following guidelines reflect my own beliefs and commitments towards parent students4\n\nBabies are welcome in class as often as necessary for support feeding relationship.\nYou are welcome to bring your child to class in order to cover unforeseeable gaps in childcare.\nIf you come with babies or toddler, I ask that you sit close to the door so that, in case your little one needs special attention and is disrupting the learning of other students, you may step outside of class until their needs are met. Seats close to the door are reserved for parents attending class with their child."
  }
]