---
title: "Complete factorial designs"
author: "Léo Belzile"
date: "`r Sys.Date()`"
output:
   xaringan::moon_reader:
      lib_dir: "libs"
      chakra: "libs/remark-latest.min.js"
      css: ["default", "css/ath-slides.css", "css/ath-inferno-fonts.css", "css/animate.css"]
      seal: false
      anchor_sections: false
      nature:
          highlightStyle: github
          highlightLines: false
          countIncrementalSlides: false
          ratio: "16:9"
      navigation:
        scroll: false
      editor_options: 
        chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(warning = FALSE, 
message = FALSE, 
fig.retina = 3, 
fig.align = "center",
fig.width = 10,
fig.asp = 0.618,
out.width = "70%")
```
```{r packages-data, echo = FALSE, include=FALSE}
library(knitr)
options(knitr.kable.NA = '')
options(tidyverse.quiet = TRUE)
options(knitr.table.format = "html")
library(tidyverse)
library(patchwork)
```
```{r xaringanExtra, echo=FALSE}
xaringanExtra::use_xaringan_extra(c("tile_view","freezeframe","panelset","clipboard","broadcast"))
```

class: center middle main-title section-title-1

# Complete factorial designs

.class-info[

**Session 5**

.light[MATH 80667A: Experimental Design and Statistical Methods <br>for Quantitative Research in Management <br>
HEC Montréal
]

]

---

name: outline
class: title title-inv-1

# Outline



.box-4.medium.sp-after-half[Factorial designs and interactions]



.box-5.medium.sp-after-half[Model formulation]

.box-6.medium.sp-after-half[Multifactorial designs]



---

layout: false
name: factorial-interaction
class: center middle section-title section-title-4 animated fadeIn

# Factorial designs and interactions

---

layout: true
class: title title-4

---

# Complete factorial designs?

.box-inv-4.sp-after[
.large[**Factorial design**]<br> study with multiple factors (subgroups)
]


.box-inv-4[.large[**Complete**]
<br>Gather observations for every subgroup]

---

# Motivating example

.box-inv-4[**Response**:<br> retention of information <br>two hours after reading a story]

.box-inv-4[**Population**:<br> children aged four]


.box-inv-4.align-left[**experimental factor 1**:<br> ending (happy or sad)]

.box-inv-4[**experimental factor 2**:<br> complexity (easy, average or hard).]




---

# Setup of design



```{r, echo=FALSE, warning=FALSE, cache = TRUE}
library(gt)
library(gtsummary)
# list of all the icons used in table
path_figure <- list("img/05/icons8-smiling-100.png",
                    "img/05/icons8-disappointed-100.png")
# making table with gt
list(
  ending = c("happy", "sad"),
  complexity = c("complicated", "average", "simple")
) |>
  purrr::cross_df() |>
  dplyr::mutate(response = rep(1:3, each = 2)) |>
  tidyr::pivot_wider(id_cols = complexity,
                     names_from = ending,
                     values_from = response) |>
  gt() |>
  # cols_hide(columns = c(ending)) |>
  data_color(
    columns = c(happy, sad),
    #c(complicated,normal,simple),
    colors = scales::col_factor(
      palette = c("#bae1ff", "#ffdfba", "#ffb3ba"),
      domain = NULL,
      ordered = TRUE,
      reverse = TRUE
    ),
    alpha = 0.8
  ) |>
  text_transform(
    locations = cells_body(columns = c(happy)),
    fn = function(x) {
      local_image(height = 80, filename = path_figure[[1]])
    }
  ) |>
  text_transform(
    locations = cells_body(columns = c(sad)),
    fn = function(x) {
      local_image(height = 80, filename = path_figure[[2]])
    }
  )  |>
  cols_width(c(happy, sad) ~ px(120)) |>
  tab_options(column_labels.font.size = 40,
              table.font.size = 40)
```


.box-inv-4[Factors are crossed]


---

# Efficiency of factorial design

.box-inv-4.sp-after.medium[Cast problem<br>as a series of one-way ANOVA <br> vs simultaneous estimation]


.box-4.medium.sp-before[Factorial designs requires<br> **fewer overall observations**]

.box-4.medium.sp-before[Can study **interactions**]

???

To study each interaction (complexity, story book ending) we would need to make three group for each comparison in rows, and one in each column. So a total of 3 one-way ANOVA each with  2 groups and 2 one-way anova with 3 groups. The two-way ANOVA will lead to 6 groups instead of 12.

---

# Interaction

.box-inv-4.sp-after.medium[
**Definition**: when the effect of one factor<br> depends on the levels of another factor.
]

.box-inv-4[
Effect together<br>
$\neq$
<br> sum of individual effects
]

---

# Interaction or profile plot
.box-inv-4.large.sp-after[Graphical display: <br>plot sample mean per category]

.box-4.sp-after-half[with uncertainty measure<br>(1 std. error for mean<br>confidence interval, etc.)]



---

# Interaction: lines are not parallel

```{r}
#| label: "interaction_plots2"
#| echo: false
#| eval: true
#| out.width: '80%'
#| fig.width: 8
#| fig.height: 3
set.seed(1234)
data_fake <- tibble::tibble(
  "ending" = factor(rep(c("happy", "sad"), each = 3)),
  "complexity" = factor(rep(c("complicated", "average", "simple"), 
                            length.out = 6)),
                
         mean = 10 + rnorm(n = 6))

g1 <- ggplot(data = data_fake,
             aes(x = complexity, y = mean)) +
  geom_line(aes(group = ending, 
                linetype = ending),
            alpha = 0.9,
            size = 1.2) +
  geom_point() + 
  # ggimage::geom_image(aes(image = image),
  #                     size = 0.1,
  #                     by = "width",
  #                     asp = 1.618) +
  geom_point(size = 2.6, aes(shape = ending)) +
  theme_classic() +
  theme(legend.position = "bottom") +
  labs(title = "")
g2 <- ggplot(data = data_fake,
             aes(
               x = ending,
               y = mean,
               group = complexity,
               color = complexity
             )) +
  scale_color_manual(values = c("#ffdfba", "#ffb3ba", "#bae1ff")) +
  geom_line(size = 1.2) +
  geom_point(size = 2.6, shape = 15) +
  theme_classic() +
  theme(legend.position = "bottom")

g1 + g2
```

---

# No interaction: parallel lines

```{r}
#| label: "interaction_plots1"
#| echo: false
#| eval: true
#| out.width: '80%'
#| fig.width: 8
#| fig.height: 3
set.seed(1234)
data_fake <- tibble::tibble(
  "ending" = factor(rep(c("happy", "sad"), each = 3)),
  "complexity" = factor(rep(c("complicated", "average", "simple"), 
                            length.out = 6))) |>
  # purrr::cross_df()  |>
  mutate(
      mean = 10 + 
      rep(rnorm(n = 2), each = 3) +
      rep(rexp(n = 3, rate = 1 / 3), length.out = 6)
# c(4,5,6,9,10,11,8,9,10)
)


g1 <- ggplot(data = data_fake,
             aes(x = complexity, y = mean)) +
  geom_line(aes(group = ending, 
                linetype = ending),
            size = 1.2) +
  # ggimage::geom_image(aes(image = image),
  #                     size = 0.1,
  #                     by = "width",
  #                     asp = 1.618) +
   geom_point(size = 2.6, aes(shape = ending)) +
  theme_classic() +
  theme(legend.position = "bottom") +
  labs(title = "Lines are parallel = no interaction")
g2 <- ggplot(data = data_fake,
             aes(
               x = ending,
               y = mean,
               group = complexity,
               color = complexity
             )) +
  scale_color_manual(values = c("#ffdfba", "#ffb3ba", "#bae1ff")) +
  geom_line(size = 1.2) +
  geom_point(size = 2.6, shape = 15) +
  theme_classic() +
  theme(legend.position = "bottom")

g1 + g2
```


---

# Interaction plot for 2 by 2 design

```{r}
#| label: 2by2-interaction
#| eval: true
#| echo: false
#| out-width: "80%"
p1 <- data.frame(
  factorA = c("a1", "a1", "a2", "a2"),
  factorB = c("b1", "b2", "b1", "b2"),
  means = c(5, 5, 5, 5)
)
p2 <- data.frame(
  factorA = c("a1", "a1", "a2", "a2"),
  factorB = c("b1", "b2", "b1", "b2"),
  means = c(10, 10, 5, 5)
)
p3 <- data.frame(
  factorA = c("a1", "a1", "a2", "a2"),
  factorB = c("b1", "b2", "b1", "b2"),
  means = c(10, 13, 5, 2)
)
p4 <- data.frame(
  factorA = c("a1", "a1", "a2", "a2"),
  factorB = c("b1", "b2", "b1", "b2"),
  means = c(5, 10, 10, 15)
)
p5 <- data.frame(
  factorA = c("a1", "a1", "a2", "a2"),
  factorB = c("b1", "b2", "b1", "b2"),
  means = c(10, 18, 5, 7)
)
p6 <- data.frame(
  factorA = c("a1", "a1", "a2", "a2"),
  factorB = c("b1", "b2", "b1", "b2"),
  means = c(5, 10, 5, 10)
)
p7 <- data.frame(
  factorA = c("a1", "a1", "a2", "a2"),
  factorB = c("b1", "b2", "b1", "b2"),
  means = c(2, 12, 5, 9)
)
p8 <- data.frame(
  factorA = c("a1", "a1", "a2", "a2"),
  factorB = c("b1", "b2", "b1", "b2"),
  means = c(5, 10, 10, 5)
)
all_22s <- rbind(p1, p2, p3, p4, p5, p6, p7, p8)
type <- factor(rep(1:8, each = 4), 
               labels = c("no effect",
                          "main effect of A only",
                          "main effect of A and interaction",
                          "both main effects",
                          "both main effects and interaction",
                          "main effect of B only",
                          "main effect of B and interaction",
                          "interaction only"))
all_22s <- cbind(all_22s, type)
options(ggplot2.discrete.colour= MetBrewer::met.brewer(name = "Hiroshige", 2))
ggplot(all_22s, 
       mapping = aes(x = factorA, 
                     y = means, 
                     type = type,
                     group = factorB, 
                     color = factorB))+
  geom_point() +
  geom_line() +
  labs(x = "factor A",
       subtitle = "mean response",
       y = "",
       color = "factor B") +
  facet_wrap(~type, nrow = 2) +
  theme_classic() +
  theme(legend.position = "bottom")
```


???

Line graph for example patterns for means for each of the possible kinds of general outcomes in a 2 by 2 design. Illustration adapted from Figure 10.2 of Crump, Navarro and Suzuki (2019) by Matthew Crump (CC BY-SA 4.0 license)

---

layout: false
name: formulation
class: center middle section-title section-title-5 animated fadeIn

# Model formulation

---

layout: true
class: title title-5

---

# Formulation of the two-way ANOVA

Two factors: $A$ (complexity) and $B$ (ending) with $n_a$ and $n_b$ levels.

Write the average response $Y_{ijr}$ of the $r$th measurement in group $(a_i, b_j)$ as
\begin{align*}
\underset{\text{response}\vphantom{b}}{Y_{ijr}} = \underset{\text{subgroup mean}}{\mu_{ij}} + \underset{\text{error term}}{\varepsilon_{ijr}}
\end{align*}
where 

- $Y_{ijr}$ is the $r$th replicate for $i$th level of factor $A$ and $j$th level of factor $B$
- $\varepsilon_{ijr}$ are independent error terms with mean zero and variance $\sigma^2$.

---
# One average for each subgroup

| $\qquad B$ `ending`<br> $A$ `complexity` $\qquad$ | $b_1$ (`happy`) | $b_2$ (`sad`)| *row mean* |
|------------|:----------:|:-----:|:-----:|
| $a_1$ (`complicated`) | $\mu_{11}$ | $\mu_{12}$ | $\mu_{1.}$ |
|  $a_2$ (`average`)  | $\mu_{21}$ | $\mu_{22}$ | $\mu_{2.}$ |
| $a_3$ (`simple`) |  $\mu_{31}$ | $\mu_{32}$ | $\mu_{3.}$ |
|*column mean* | $\mu_{.1}$ | $\mu_{.2}$ | $\mu$ |


---

# Row, column and overall average

.pull-left[

- Mean of $A_i$ (average of row $i$): 
$$\mu_{i.} = \frac{\mu_{i1} + \cdots + \mu_{in_b}}{n_b}$$

- Mean of $B_j$ (average of column $j$):
$$\mu_{.j} = \frac{\mu_{1j} + \cdots + \mu_{n_aj}}{n_a}$$

]
.pull-right[
- Overall average (overall all rows and columns):
$$\mu = \frac{\sum_{i=1}^{n_a} \sum_{j=1}^{n_b} \mu_{ij}}{n_an_b}$$

]

---


# Vocabulary of effects
.pull-left[
.box-5[Definitions]
- .color-5[**simple effects**]: difference between levels of one in a fixed combination of others (change in difficulty for happy ending)
- .color-5[**main effects**]: differences relative to average for each condition of a factor (happy vs sad ending)
- .color-5[**interaction effects**]: when simple effects differ depending on levels of another factor
]
.pull-right[
.box-5[What it means relative to the table]

- .color-5[**simple effects**] are comparisons between cell averages within a given row or column


- .color-5[**main effects**] are comparisons between row or column averages


- .color-5[**interaction effects**] are difference relative to the row or column average

]
---


# Contrasts

Suppose the order of the coefficients is factor $A$ (complexity, 3 levels, complicated/average/easy) and factor $B$ (ending, 2 levels, happy/sad).

| test | $\mu_{11}$ | $\mu_{12}$ | $\mu_{21}$ | $\mu_{22}$ | $\mu_{31}$ | $\mu_{32}$ |
|:--|--:|--:|--:|--:|--:|--:|
| main effect $A$ (complicated vs average) |  $1$ | $1$ | $-1$ |  $-1$ | $0$ | $0$ |
| main effect $A$ (complicated vs simple) |    $1$ |  $1$ | $0$ | $0$ | $-1$ |  $-1$ |
| main effect $B$ (happy vs sad) |    $1$ |  $-1$ | $1$ |  $-1$ | $1$ | $-1$ |
| interaction $AB$ (comp. vs av, happy vs sad) | $1$ | $-1$ | $-1$ | $1$ | $0$ | $0$ |
| interaction $AB$ (comp. vs easy, happy vs sad) |  $1$ | $-1$ | $0$ | $0$ | $-1$ | $1$ |

---

# Hypothesis tests for main effects

Generally, need to compare multiple effects at once
.box-inv-5.sp-after-half[
Main effect of factor $A$
]

$\mathscr{H}_0$: $\mu_{1.} = \cdots = \mu_{a.}$ vs $\mathscr{H}_a$: at least two marginal means of $A$ are different
.box-inv-5.sp-after-half[
Main effect of factor $B$
]

$\mathscr{H}_0$: $\mu_{.1} = \cdots = \mu_{.b}$ vs $\mathscr{H}_a$: at least two marginal means of $B$ are different.

---
# Equivalent formulation of the two-way ANOVA

Write the model for a response variable $Y$ in terms of two factors $a_i$, $b_j$.

$$Y_{ijr} = \mu + \alpha_i + \beta_j + (\alpha\beta)_{ij} + \varepsilon_{ijr}$$

where 
- $\alpha_i = \mu_{i.} - \mu$
    - mean of level $a_i$ minus overall mean.
- $\beta_j  = \mu_{.j} - \mu$
    - mean of level $b_j$ minus overall mean.
- $(\alpha\beta)_{ij} = \mu_{ij} - \mu_{i.} - \mu_{.j} + \mu$
    - the interaction term for $a_i$ and $b_j$.

---

# One average for each subgroup

.small[

| $\qquad B$ `ending`<br> $A$ `complexity` $\qquad$ | $b_1$ (`happy`) | $b_2$ (`sad`)| *row mean* |
|------------|:----------:|:-----:|:-----:|
| $a_1$ (`complicated`) | $\mu + \alpha_1 + \beta_1 + (\alpha\beta)_{11}$ | $\mu + \alpha_1 + \beta_2 + (\alpha\beta)_{12}$ | $\mu + \alpha_1$ |
|  $a_2$ (`average`)  | $\mu + \alpha_2 + \beta_1 + (\alpha\beta)_{21}$ | $\mu + \alpha_2 + \beta_2 + (\alpha\beta)_{22}$ | $\mu + \alpha_2$ |
| $a_3$ (`simple`) |  $\mu + \alpha_3 + \beta_1 + (\alpha\beta)_{31}$ | $\mu + \alpha_3 + \beta_2 + (\alpha\beta)_{32}$ | $\mu + \alpha_3$ |
|*column mean* | $\mu + \beta_1$ | $\mu + \beta_2$ | $\mu$ |

]


.box-inv-5[More parameters than data cells!]

The model in terms of $\alpha$, $\beta$ and $(\alpha\beta)$ is overparametrized.


---


# Sum-to-zero parametrization

.box-inv-5[Too many parameters!]


Impose sum to zero constraints

$$\sum_{i=1}^{n_a} \alpha_i=0, \quad \sum_{j=1}^{n_b} \beta_j=0, \quad  \sum_{j=1}^{n_b} (\alpha\beta)_{ij}=0, \quad \sum_{i=1}^{n_a} (\alpha\beta)_{ij}=0.$$

which imposes $1 +  n_a + n_b$ constraints.

---

# Why use the sum to zero parametrization?

- Testing for main effect of $A$: $$\mathscr{H}_0: \alpha_1 = \cdots = \alpha_{n_a} = 0$$
- Testing for main effect of $B$: $$\mathscr{H}_0: \beta_1 = \cdots = \beta_{n_b} = 0$$ 
- Testing for interaction between $A$ and $B$: $$\mathscr{H}_0: (\alpha\beta)_{11} = \cdots = (\alpha\beta)_{n_an_b} = 0$$

In all cases, alternative is that at least two coefficients are different.

---

# Seeking balance

.box-inv-5.sp-after.medium[
**Balanced sample**<br>
(equal nb of obs per group)

]

.box-inv-5[
With $n_r$ replications per subgroup,<br>total sample size is $n = n_an_bn_r$.
]

---

# Why balanced design?

With equal variance, this is the optimal allocation of treatment unit.

.box-inv-5.sp-after.medium[maximize power]

Estimated means for main and total effects correspond to marginal averages.

.box-inv-5.sp-after.medium[equiweighting]

Unambiguous decomposition of effects of $A$, $B$ and interaction.

.box-inv-5.sp-after.medium[orthogonality]

---

# Rewriting observations


\begin{align*}
\underset{\text{obs vs grand mean}}{(y_{ijr} - \widehat{\mu})} &= 
\underset{\text{row mean vs grand mean}}{(\widehat{\mu}_{i.} - \widehat{\mu})} \\& +\underset{\text{col mean vs grand mean}}{(\widehat{\mu}_{.j} - \widehat{\mu})} \\&+
\underset{\text{cell mean vs additive effect}}{(\widehat{\mu}_{ij} - \widehat{\mu}_{i.} - \widehat{\mu}_{.j}+ \widehat{\mu})} \\&+ \underset{\text{obs vs cell mean}}{(y_{ijr} - \widehat{\mu}_{ij})}
\end{align*}

---

# Decomposing variability

Constructing statistics as before by decomposing variability into blocks.

We can square both sides and sum over all observations.

With balanced design, all cross terms cancel, leaving us with the .color-5[**sum of square**] decomposition

$$\mathsf{SS}_{\text{total}} = \mathsf{SS}_A + \mathsf{SS}_B + \mathsf{SS}_{AB} + \mathsf{SS}_{\text{resid}}.$$

---

# Sum of square decomposition

The sum of square decomposition

$$\mathsf{SS}_{\text{total}} = \mathsf{SS}_A + \mathsf{SS}_B + \mathsf{SS}_{AB} + \mathsf{SS}_{\text{resid}}.$$
is an estimator of the population variance decomposition
$$\sigma^2_{\text{total}} = \sigma^2_A + \sigma^2_{B} + \sigma^2_{AB} + \sigma^2_{\text{resid}}.$$
where $\sigma^2_A = n_a^{-1}\sum_{i=1}^{n_a} \alpha_i^2$, $\sigma^2_{AB} = (n_an_b)^{-1} \sum_{i=1}^{n_a} \sum_{j=1}^{n_b} (\alpha\beta)^2_{ij}$, etc.


Take ratio of variability (effect relative to residual) and standardize numerator and denominator to build an $F$ statistic.


---
# Analysis of variance table


.small[

| term | degrees of freedom | mean square | $F$ | 
|------|--------|------|--------|
| $A$  | $n_a-1$   | $\mathsf{MS}_{A}=\mathsf{SS}_A/(n_a-1)$ | $\mathsf{MS}_{A}/\mathsf{MS}_{\text{res}}$ |
| $B$  | $n_b-1$   | $\mathsf{MS}_{B}=\mathsf{SS}_B/(n_b-1)$ | $\mathsf{MS}_{B}/\mathsf{MS}_{\text{res}}$ |
| $AB$ | $(n_a-1)(n_b-1)$ | $\mathsf{MS}_{AB}=\mathsf{SS}_{AB}/\{(n_a-1)(n_b-1)\}$ | $\mathsf{MS}_{AB}/\mathsf{MS}_{\text{res}}$ |
| residuals | $n-n_an_b$ | $\mathsf{MS}_{\text{resid}}=\mathsf{SS}_{\text{res}}/ (n-ab)$ | |
| total | $n-1$ | | 

]

Read the table backward (starting with the interaction).
- If there is a significant interaction, the main effects are **not** of interest and potentially misleading.

---

# Intuition behind degrees of freedom

| $\qquad B$ `ending`<br> $A$ `complexity` $\qquad$ | $b_1$ (`happy`) | $b_2$ (`sad`)| *row mean* |
|------------|:----------:|:-----:|:-----:|
| $a_1$ (`complicated`) | $\mu_{11}$ | $\mathsf{X}$ | $\mu_{1.}$ |
|  $a_2$ (`average`)  | $\mu_{21}$ | $\mathsf{X}$  | $\mu_{2.}$ |
| $a_3$ (`simple`) |  $\mathsf{X}$  | $\mathsf{X}$  | $\mathsf{X}$ |
|*column mean* | $\mu_{.1}$ | $\mathsf{X}$ | $\mu$ |

.small[ 
Terms with $\mathsf{X}$ are fully determined by row/column/total averages

]

---

# Multiplicity correction

With equal sample size and equal variance, usual recipes for ANOVA hold.

Correction depends on the effect: e.g., for factor $A$, the critical values are

- Bonferroni: $1-\alpha/(2m)$ quantile of $\mathsf{St}(n-n_an_b)$
- Tukey: Studentized range (`qtukey`)
   - level $1-\alpha/2$, $n_a$ groups, $n-n_an_b$ degrees of freedom.
- Scheffé: critical value is $\{(a-1) \mathfrak{f}_{1-\alpha}\}^{1/2}$
   - $\mathfrak{f}_{1-\alpha}$ is $1-\alpha$ quantile of $\mathsf{F}(\nu_1 = n_a-1, \nu_2 = n-n_an_b)$.

Software implementations available in `emmeans` in **R**.

---


layout: false
name: factorial-designs
class: center middle section-title section-title-5 animated fadeIn

# Numerical example

---

layout: false
name: factorial-designs
class: center middle section-title section-title-6 animated fadeIn

# Multifactorial designs

---

class: title title-6
# Beyond two factors

We can consider multiple factors $A$, $B$, $C$, $\ldots$ with respectively $n_a$, $n_b$, $n_c$, $\ldots$ levels and with $n_r$ replications for each.

The total number of treatment combinations is 

.box-inv-6.sp-after-half[
$n_a \times n_b \times n_c \times \cdots$
]


--

.box-6.medium[
**Curse of dimensionality**
]

---

class: title title-6
# Full three-way ANOVA model

Each cell of the cube is allowed to have a different mean

$$\begin{align*}
\underset{\text{response}\vphantom{cell}}{Y_{ijkr}\vphantom{\mu_{j}}} = \underset{\text{cell mean}}{\mu_{ijk}} + \underset{\text{error}\vphantom{cell}}{\varepsilon_{ijkr}\vphantom{\mu_{j}}}
\end{align*}$$
with $\varepsilon_{ijkt}$ are independent error term for 
- row $i$
- column $j$
- depth $k$
- replication $r$

---
class: title title-6
# Parametrization of a three-way ANOVA model

With the **sum-to-zero** parametrization with factors $A$, $B$ and $C$, write the response as

$$\begin{align*}\underset{\text{theoretical average}}{\mathsf{E}(Y_{ijkr})} &= \quad \underset{\text{global mean}}{\mu} \\ &\quad +\underset{\text{main effects}}{\alpha_i + \beta_j + \gamma_k}  \\ & \quad + \underset{\text{two-way interactions}}{(\alpha\beta)_{ij} + (\alpha\gamma)_{ik} + (\beta\gamma)_{jk}} \\ & \quad + \underset{\text{three-way interaction}}{(\alpha\beta\gamma)_{ijk}}\end{align*}$$

---
.small[
```{r cube1, out.width = '20%', echo = FALSE,  fig.show = 'hold', eval = TRUE, fig.cap = "global mean, row, column and depth main effects"}
knitr::include_graphics("img/05/cube.png")
knitr::include_graphics("img/05/cube_rows.png")
knitr::include_graphics("img/05/cube_column.png")
knitr::include_graphics("img/05/cube_depth.png")
```
]
.small[
```{r cube2, out.width = '20%', echo = FALSE, eval = TRUE, fig.show = 'hold', fig.cap = "row/col, row/depth and col/depth interactions and three-way interaction."}

knitr::include_graphics("img/05/cube_rowcol.png")
knitr::include_graphics("img/05/cube_rowdepth.png")
knitr::include_graphics("img/05/cube_coldepth.png")
knitr::include_graphics("img/05/cube_all.png")
```
]

---
class: title title-6
# Example of three-way design

.small[
Petty, Cacioppo and Heesacker (1981). Effects of rhetorical questions on persuasion: A cognitive response analysis. Journal of Personality and Social Psychology.

A $2 \times 2 \times 2$ factorial design with 8 treatments groups and $n=160$ undergraduates.

Setup: should a comprehensive exam be administered to bachelor students in their final year?

- **Response** Likert scale on $-5$ (do not agree at all) to $5$ (completely agree)
- **Factors**
- $A$: strength of the argument (`strong` or `weak`)
- $B$: involvement of students `low` (far away, in a long time) or  `high` (next year, at their university)
- $C$: style of argument, either `regular` form or `rhetorical` (Don't you think?, ...)
]

---
class: title title-6

# Interaction plot

.small[
Interaction plot for a  $2 \times 2 \times 2$ factorial design from Petty, Cacioppo and Heesacker (1981)
]

```{r interactionpetty, echo = FALSE, fig.retina = 3, fig.width=6,fig.height=2,out.width = '70%'}
petty <- tibble(agreement = c(0.04,0.75,-0.1,-0.66,0.61,0.05,-0.46,-0.24),
"strength" = factor(rep(rep(c("strong","weak"), each = 2), length.out = 8)),
"involvement" = relevel(factor(rep(c("low","high"), length.out = 8)), ref = "low"),
"style" = factor(rep(c("regular","rhetorical"), each = 4)))
ggplot(data = petty, 
aes(x = involvement, y = agreement, col = strength, group = strength)) + 
geom_line(stat = "identity") + 
facet_wrap(~style) + 
  labs(y = "", 
       subtitle = "mean agreement rating") + 
theme_bw() + theme(legend.position = "bottom")
```

???

p.472 of Keppel and Wickens


---
class: title title-6
#  The microwave popcorn experiment

What is the best brand of microwave popcorn? 

- **Factors**
- brand (two national, one local)
- power: 500W and 600W
- time: 4, 4.5 and 5 minutes
- **Response**: <s>weight</s>, <s>volume</s>, <s>number</s>, percentage of popped kernels.
- Pilot study showed average of 70% overall popped kernels (10% standard dev), timing values reasonable
- Power calculation suggested at least $r=4$ replicates, but researchers proceeded with $r=2$...

---

```{r popcorn_pre, echo = FALSE, eval = TRUE}
# Somehow there is an error message when knitting
library(tidyverse) #load packages
# Sum-to-zero parametrization
data(popcorn, package = "hecedsm")
model <- aov(percentage ~ brand * power * time, 
             data = popcorn)
# ANOVA table
anova_table <- anova(model) # 'anova' is for balanced designs
```

.panelset[

.panel[.panel-name[ANOVA]
```{r popcorn_qqplot, echo = TRUE, eval = FALSE}
data(popcorn, package = 'hecedsm')
# Fit model with three-way interaction
model <- aov(percentage ~ brand*power*time,
             data = popcorn)
# ANOVA table - 'anova' is ONLY for balanced designs
anova_table <- anova(model) 
# Quantile-quantile plot
car::qqPlot(model)
```

.small[Model assumptions: plots and tests are meaningless with $n_r=2$ replications per group...]

]

.panel[.panel-name[QQ-plot]

```{r popcornplotqqplot, out.width = '35%', fig.retina = 3, fig.asp = 1,eval = TRUE, echo = FALSE}

car::qqPlot(model, # points should be on straight line!
id = FALSE, 
ylab = 'studentized residuals',
xlab = "Student-t quantiles")
```

All points fall roughly on a straight line.

]

.panel[.panel-name[**R** code]
```{r popcorn_plot, echo = TRUE, eval = FALSE, message = FALSE}
popcorn |> 
   group_by(brand, time, power) |>
   summarize(meanp = mean(percentage)) |>
ggplot(mapping = aes(x = power, 
                     y = meanp, 
                     col = time, 
                     group = time)) + 
  geom_line() + 
  facet_wrap(~brand)
```
]


.panel[.panel-name[Interaction plot]

```{r popcornplot2, echo = FALSE, eval = TRUE, message = FALSE, cache = TRUE, fig.asp = 0.35, out.width = '80%'}
popcorn |>
  group_by(brand, time, power) |>
  summarize(mean_percentage = mean(percentage)) |>
  ggplot(aes(
    x = power,
    y = mean_percentage,
    col = time,
    group = time
  )) +
  geom_line() +
  facet_wrap( ~ brand) +
  labs(y = "percentage of\n popped kernels",
       col = "time (min)",
       x = "power (W)") +
  theme_bw() +
  theme(legend.position = "bottom")
```

No evidence of three-way interaction (hard to tell with $r=2$ replications).
]


]

---

class: title title-6
# Analysis of variance table for balanced designs

.small[

| terms | degrees of freedom | 
|:---:|:-----|:-------|
| $A$ | $n_a-1$ | 
| $B$ | $n_b-1$ | 
| $C$ | $n_c-1$ | 
| $AB$ | $(n_a-1)(n_b-1)$ | 
| $AC$ | $(n_a-1)(n_c-1)$ | 
| $BC$ | $(n_b-1)(n_c-1)$ | 
| $ABC$ | ${\small (n_a-1)(n_b-1)(n_c-1)}$ | 
| $\text{residual}$ | $n_an_bn_c(R-1)$ | 
| $\text{total}$ | $n_an_bn_cn_r-1$ | 

]

---

```{r printanovaPopcorn, echo = FALSE, eval = TRUE}
knitr::kable(anova_table,
digits = c(0,2,2,2,3),
caption = "Analysis of variance table for microwave-popcorn",
col.names = c("Degrees of freedom",
     "Sum of squares",
     "Mean square",
     "F statistic",
     "p-value")) |>
kableExtra::kable_styling(position = "center")
```

---
class: title title-6
# Omitting terms in a factorial design

The more levels and factors, the more parameters to estimate (and replications needed)
- Costly to get enough observations / power
- The assumption of normality becomes more critical when $r=2$!

It may be useful not to consider some interactions if they are known or (strongly) suspected not to be present

- If important interactions are omitted from the model, biased estimates/output!

---
class: title title-6
# Guidelines for the interpretation of effects

Start with the most complicated term (top down)

- If the three-way interaction $ABC$ is significative:
    - don't interpret main effects or two-way interactions!
    - comparison is done cell by cell within each level
- If the $ABC$ term isn't significative:
    - can marginalize and interpret lower order terms
    - back to a series of two-way ANOVAs

---

class: title title-6

# What contrasts are of interest?

- Can view a three-way ANOVA as a series of one-way ANOVA or two-way ANOVAs...

Depending on the goal, could compare for variable $A$
- marginal contrast $\psi_A$ (averaging over $B$ and $C$)
- marginal conditional contrast for particular subgroup: $\psi_A$ within $c_1$
- contrast involving two variables: $\psi_{AB}$
- contrast differences between treatment at $\psi_A \times B$, averaging over $C$.
- etc.

See helper code and chapter 22 of Keppel & Wickens (2004) for a detailed example.

---
class: title title-6
# Effects and contrasts for microwave-popcorn

Following preplanned comparisons

- Which combo (brand, power, time) gives highest popping rate? (pairwise comparisons of all combos)
- Best brand overall (marginal means marginalizing over power and time, assuming no interaction)
- Effect of time and power on percentage of popped kernels 
- pairwise comparison of time $\times$ power
- main effect of power
- main effect of time

---

class: title title-6
# Preplanned comparisons using `emmeans`


Let $A$=brand, $B$=power, $C$=time

Compare difference between percentage of popped kernels for 4.5 versus 5 minutes, for brands 1 and 2

$$\mathscr{H}_0: (\mu_{1.2} -\mu_{1.3}) - (\mu_{2.2} - \mu_{2.3}) = 0$$

.small[
```{r plannedcomparisonspopcorn, echo = TRUE, eval = FALSE}
library(emmeans)
# marginal means
emm_popcorn_AC <- emmeans(model, 
                          specs = c("brand","time"))
contrast_list <- 
  list(
    brand12with4.5vs5min = c(0, 0, 0, 1, -1, 0, -1, 1,0))
contrast(emm_popcorn_AC,  # marginal mean (no time)
         method = contrast_list) # list of contrasts
```

```{r Scheffebyhand, echo = FALSE, eval = FALSE}
# Scheffé adjustment by hand 
# emmeans is off because of marginalization - 
# could be solved but specifying the 18 dim vector for contrast...
Scrit <- sqrt(17*qf(0.99, 17, 18)) # 18 cells, but all in terms of 17 combos of differences
# qf() is 99% quantile of F distribution 
# with 17 df and 18 df=(degrees of freedom of residual, 36 obs - 18 param)
# with(contrast_popcorn, c(lower = estimate - Scrit*SE, upper = estimate + Scrit*SE))
```
]

---

class: title title-6
# Preplanned comparisons

Compare all three times (4, 4.5 and 5 minutes)

At level 99% with Tukey's HSD method

- Careful! Potentially misleading because there is a `brand * time` interaction present.

```{r plannedcomparisons2popcorn, echo = TRUE, eval = FALSE}
# List of variables to keep go in `specs`: keep only time
emm_popcorn_C <- emmeans(model, specs = "time")
pairs(emm_popcorn_C, 
      adjust = "tukey", 
      level = 0.99, 
      infer = TRUE)

```

